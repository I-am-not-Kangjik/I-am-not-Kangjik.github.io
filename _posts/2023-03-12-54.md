---
title: 플레이데이터 딥러닝 프로젝트 회고
date: 2023-03-12 12:19:00 +0900
categories: [project, 프로젝트 회고록]
tags: [playdata, memoir, project]     # TAG names should always be lowercase
---
## 프로젝트 결과물 링크(Github Repository)

[https://github.com/malcano/deeplearning_mini_pj](https://github.com/malcano/deeplearning_mini_pj)

[https://github.com/malcano/aws_flask_server_deepl_pj](https://github.com/malcano/aws_flask_server_deepl_pj)

## 프로젝트 결과물 링크(youtube)

[https://youtube.com/shorts/s5RV3fm0Bw4?feature=share](https://youtube.com/shorts/s5RV3fm0Bw4?feature=share)

## 개요

머신러닝 프로젝트가 끝나자 마자 바로 딥러닝 수업을 들었다.

2주 동안 CNN, RNN 등의 개념을 배우고, yolo v3, LSTM, GRU, BiLSTM 등의 모델을 사용해봤다.

머신러닝과는 차원이 다른 fit 속도와, input shape에서 상당한 어려움을 겪었다…

저번 프로젝트와 마찬가지로,

이 2주간의 배운 딥러닝 지식을 가지고 자유로운 주제로 딥러닝 프로젝트를 진행하는 것이었다.

한 팀당 6명씩 구성됐다.

## 프로젝트 주제

우리 팀의 주제는 꽃BERT였다.

꽃BERT란?

ai hub의 감성 대화 말뭉치를 통해 모델을 학습시키고,

사용자의 현재 기분을 담은 문장을 입력받아

학습시킨 모델을 통해 감정과 상황을 분석해

해당 감정에 도움이 되는 꽃말을 기반으로 꽃을 추천해 주는 자연어 처리 + 추천 시스템이다.

## 개인이 맡은 역할

우선 데이터 셋이 문장을 기반으로 6가지 감정 대분류와, 12가지 상황 키워드로 구성되어 있어

한 가지 감정과 상황으로 구분 짓기 어려운 문장들이 꽤 있었다.

그래서 공통적으로 데이터 셋을 검사/확인하고, 이상치 데이터를 라벨링 했다.

그 내용을 바탕으로 한 명이 tokenizer, stopwords, 그리고 LSTM을 활용한 초기 모델을 구현했고

해당 모델은 75점 정도의 정확도를 보였다.

모두가 fine-tuning을 진행했는데, 나는 BiLSTM을 사용해 76.9의 성능을 보이는 모델을 만들고,

추가로 BiLSTM + attention 을 사용한 모델을 구현했으나 성능이 생각보다 나와주지 않았다.

최종적으로 팀원 중 한 분이 koBERT에 전이 학습을 진행시켜 99점(...)의 정확도를 갖는 모델을 만들었다.

이후 나는 입력창, 선택창, 결과창 3개로 구성된 웹페이지의 프론트엔드를 전담했다.

## 후기

### 1.

자연어 처리를 통한 감성 분류를 진행하며 하나로 단정 짓기 어려운 모호한 단어들이 많이 있었다.

새삼 챗 GPT가 대단하게 느껴졌다.

### 2.

우리가 구현한 초기 모델이 75점의 정확도를,

fine-tuning을 진행해 성능을 올린 모델이 77점의 정확도를 보였지만,

KoBERT를 사용하니 99점의 정확도가 나와 경악을 금치 못했다.

KoBERT가 최고인 것 같다.

### 3.

flask_asset과 scss를 처음 사용해 보았는데

렌더링 하고 적용하는 과정이 낯설어 어려움을 겪었다.

하지만 이틀 사이 3페이지를 완성하다 보니,

숙달된 조교가 된 기분이 들었다.

### 4.

백엔드를 담당한 팀원이 aws를 사용해 배포해서

나에겐 처음으로 배포를 경험해 본 프로젝트가 됐다.

그래서 더 잘하고 싶다는 욕심이 있어,

의도한 프론트엔드 부분이 잘 구현되지 않을 때 더욱 힘들었다..